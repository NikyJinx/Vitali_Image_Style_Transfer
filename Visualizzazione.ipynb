{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa58a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessari\n",
    "import torch\n",
    "#import transformer\n",
    "import transformer_norm\n",
    "import os\n",
    "import utils\n",
    "import time\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a32165a-0143-4e61-a9d1-47e569f19448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_7732\\3102023421.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(style_transform_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stylized 70jq6imm9g57.jpg in 0.2871739864349365 seconds.\n",
      "Stylized aqua.jpg in 0.07106471061706543 seconds.\n",
      "Stylized colosseum-rome-dusk-1-1.jpg in 0.025022506713867188 seconds.\n",
      "Stylized drake.jpg in 0.08107423782348633 seconds.\n",
      "Stylized gojo.jpg in 0.038034915924072266 seconds.\n",
      "Stylized guts_angry.jpg in 0.017015695571899414 seconds.\n",
      "Stylized image.jpg in 0.21919894218444824 seconds.\n",
      "Stylized image1.jpg in 0.039034366607666016 seconds.\n",
      "Stylized IMG1.jpg in 0.019015789031982422 seconds.\n",
      "Stylized jinx.jpg in 0.0790717601776123 seconds.\n",
      "Stylized P1.jpg in 0.6345763206481934 seconds.\n",
      "Stylized Pantheon_Rom_1_cropped.jpg in 0.021020174026489258 seconds.\n",
      "Stylized PXL_20230908_230949088.jpg in 0.9469826221466064 seconds.\n",
      "Stylized PXL_20230909_130056726.jpg in 0.6342096328735352 seconds.\n",
      "Stylized PXL_20240412_104913318.jpg in 0.7056410312652588 seconds.\n",
      "Stylized PXL_20240413_095450371 - Copia.jpg in 0.02202010154724121 seconds.\n",
      "Stylized PXL_20240413_095450371.jpg in 0.46942567825317383 seconds.\n",
      "Stylized PXL_20240415_153216925.jpg in 0.7046403884887695 seconds.\n",
      "Stylized rebecca.jpg in 0.15213871002197266 seconds.\n",
      "Stylized ulro.jpg in 0.8197455406188965 seconds.\n",
      "Stylized up-diliman.jpg in 0.09708833694458008 seconds.\n",
      "Stylized village3d.jpg in 0.14913606643676758 seconds.\n",
      "Stylized york.jpg in 0.09108448028564453 seconds.\n",
      "All images stylized and saved in images/input\\output\\kill\\coco\n"
     ]
    }
   ],
   "source": [
    "#### Generazione Imagini trasferimento stile \n",
    "# il codice chiederà di inserire il path della cartella con tutte le imagini da trasformare\n",
    "# inserire il path completo tipo C:\\Users\\Name\\Desktop\\Folder \n",
    "# oppure inserire solo le sottocartelle della cartella corrente se il file si trova gia in Desktop inserire solo Folder\n",
    "# se si usa il tranformer con i meccanismi di attenzione alcune imagini verranno skippate\n",
    "# se si voglono comunque processare usare il codice sottostante a questo\n",
    "\n",
    "# Pulizia cache GPU\n",
    "torch.cuda.empty_cache() \n",
    "# Inserire path dei pesi della rete addestrata da utilizzare\n",
    "STYLE_TRANSFORM_PATH = \"/DL_Prog/content/kill/coco/transformer_weight.pth\"\n",
    "#STYLE_TRANSFORM_PATH = \"/DL_Prog/content/kill/coco/checkpoint_16000.pth\"\n",
    "# Impostare False per non mantenere i colori originali dell'immagine di contenuto (vengono usati i colori dell'immagine di stile)\n",
    "# Impostare True per mantenere i colori originali dell'immagine di contenuto \n",
    "PRESERVE_COLOR = False\n",
    "\n",
    "def stylize_folder(content_folder, style_transform_path, preserve_color=False):\n",
    "    \"\"\"\n",
    "    Stylizes all images in the content_folder and saves them in new nested folders based on the\n",
    "    style_transform_path.\n",
    "    \n",
    "    Parameters:\n",
    "    - content_folder: Path to the folder containing content images.\n",
    "    - style_transform_path: Path to the style transformer model.\n",
    "    - preserve_color: Boolean indicating whether to preserve the colors of the content images.\n",
    "    \"\"\"\n",
    "    # Device\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ##############################################################################################################################################################\n",
    "    # Load Transformer Network SELEZIONARE IL TRANF GIUSTO\n",
    "    ##########################################################################################################################################################\n",
    "    # Caricamento dei pesi della rete di trasformazione di stile e trasferimento del modello sul dispositivo scelto.\n",
    "    \n",
    "    #net = transformer.TransformerNetworkTanhWithAttention()\n",
    "    net = transformer_norm.TransformerNetworkTanh()\n",
    "\n",
    "    net.load_state_dict(torch.load(style_transform_path))\n",
    "    net = net.to(device)\n",
    "\n",
    "    # Extract the first and second subfolder names from the style_transform_path\n",
    "    first_subfolder_name = style_transform_path.split('/')[3]\n",
    "    second_subfolder_name = '/'.join(style_transform_path.split('/')[4:-1])\n",
    "\n",
    "    # Create output folder with the extracted subfolder names\n",
    "    output_folder = os.path.join(content_folder, \"output\", first_subfolder_name, second_subfolder_name)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Stylize every image in the content folder\n",
    "    # Recupero di tutte le immagini compatibili (JPG, JPEG, PNG) dalla cartella di contenuti e iterazione su ciascuna. \n",
    "    images = [img for img in os.listdir(content_folder) if img.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    with torch.no_grad():\n",
    "        for image_name in images:\n",
    "            try:\n",
    "                # Free-up unneeded cuda memory\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # Load content image\n",
    "                content_image_path = os.path.join(content_folder, image_name)\n",
    "                content_image = utils.load_image(content_image_path)\n",
    "                content_tensor = utils.itot(content_image).to(device)\n",
    "\n",
    "                # Generate stylized image\n",
    "                starttime = time.time()\n",
    "                generated_tensor = net(content_tensor)\n",
    "                generated_image = utils.ttoi(generated_tensor.detach())\n",
    "                if preserve_color:\n",
    "                    generated_image = utils.transfer_color(content_image, generated_image)\n",
    "                print(f\"Stylized {image_name} in {time.time() - starttime} seconds.\")\n",
    "\n",
    "                # Save stylized image\n",
    "                output_image_path = os.path.join(output_folder, image_name)\n",
    "                utils.saveimg(generated_image, output_image_path)\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                # Catch out-of-memory errors and skip the image\n",
    "                if 'out of memory' in str(e):\n",
    "                    \n",
    "                    print(f\"Skipping {image_name} due to memory limitations.\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    print(f\"All images stylized and saved in {output_folder}\")\n",
    "\n",
    "# Example usage\n",
    "content_folder = input(\"Enter the folder path containing the images: \")\n",
    "stylize_folder(content_folder, STYLE_TRANSFORM_PATH, PRESERVE_COLOR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec7e9e12-d494-4fde-9fee-63a63f31ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_2016\\2269236996.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(style_transform_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stylized 70jq6imm9g57.jpg in 0.37085962295532227 seconds.\n",
      "Stylized 70jq6imm9g571.jpg in 0.14212942123413086 seconds.\n",
      "Resized images/input\\aqua.jpg to 900x506 and saved as images/input\\resized\\aqua_resized.jpg.\n",
      "Stylized aqua.jpg in 0.2210242748260498 seconds.\n",
      "Stylized colosseum-rome-dusk-1-1.jpg in 0.15013647079467773 seconds.\n",
      "Resized images/input\\drake.jpg to 700x700 and saved as images/input\\resized\\drake_resized.jpg.\n",
      "Stylized drake.jpg in 0.25122857093811035 seconds.\n",
      "Resized images/input\\gojo.jpg to 700x700 and saved as images/input\\resized\\gojo_resized.jpg.\n",
      "Stylized gojo.jpg in 0.25623345375061035 seconds.\n",
      "Stylized guts_angry.jpg in 0.08507752418518066 seconds.\n",
      "Resized images/input\\image.jpg to 700x472 and saved as images/input\\resized\\image_resized.jpg.\n",
      "Stylized image.jpg in 0.12211179733276367 seconds.\n",
      "Stylized image1.jpg in 0.1191093921661377 seconds.\n",
      "Stylized IMG1.jpg in 0.11328339576721191 seconds.\n",
      "Resized images/input\\jinx.jpg to 700x394 and saved as images/input\\resized\\jinx_resized.jpg.\n",
      "Stylized jinx.jpg in 0.08808064460754395 seconds.\n",
      "Resized images/input\\P1.jpg to 700x525 and saved as images/input\\resized\\P1_resized.jpg.\n",
      "Stylized P1.jpg in 0.14913582801818848 seconds.\n",
      "Stylized Pantheon_Rom_1_cropped.jpg in 0.14413094520568848 seconds.\n",
      "Resized images/input\\PXL_20230908_230949088.jpg to 700x525 and saved as images/input\\resized\\PXL_20230908_230949088_resized.jpg.\n",
      "Stylized PXL_20230908_230949088.jpg in 0.14713358879089355 seconds.\n",
      "Resized images/input\\PXL_20230909_130056726.jpg to 700x525 and saved as images/input\\resized\\PXL_20230909_130056726_resized.jpg.\n",
      "Stylized PXL_20230909_130056726.jpg in 0.1461331844329834 seconds.\n",
      "Resized images/input\\PXL_20240412_104913318.jpg to 900x506 and saved as images/input\\resized\\PXL_20240412_104913318_resized.jpg.\n",
      "Stylized PXL_20240412_104913318.jpg in 0.2202005386352539 seconds.\n",
      "Stylized PXL_20240413_095450371 - Copia.jpg in 0.15213823318481445 seconds.\n",
      "Resized images/input\\PXL_20240413_095450371.jpg to 900x506 and saved as images/input\\resized\\PXL_20240413_095450371_resized.jpg.\n",
      "Stylized PXL_20240413_095450371.jpg in 0.2202000617980957 seconds.\n",
      "Resized images/input\\PXL_20240415_153216925.jpg to 900x506 and saved as images/input\\resized\\PXL_20240415_153216925_resized.jpg.\n",
      "Stylized PXL_20240415_153216925.jpg in 0.22120141983032227 seconds.\n",
      "Resized images/input\\rebecca.jpg to 599x700 and saved as images/input\\resized\\rebecca_resized.jpg.\n",
      "Stylized rebecca.jpg in 0.18717074394226074 seconds.\n",
      "Resized images/input\\ulro.jpg to 700x700 and saved as images/input\\resized\\ulro_resized.jpg.\n",
      "Stylized ulro.jpg in 0.2502272129058838 seconds.\n",
      "Resized images/input\\up-diliman.jpg to 700x466 and saved as images/input\\resized\\up-diliman_resized.jpg.\n",
      "Stylized up-diliman.jpg in 0.11710691452026367 seconds.\n",
      "Resized images/input\\village3d.jpg to 900x476 and saved as images/input\\resized\\village3d_resized.jpg.\n",
      "Stylized village3d.jpg in 0.1961808204650879 seconds.\n",
      "Resized images/input\\york.jpg to 700x700 and saved as images/input\\resized\\york_resized.jpg.\n",
      "Stylized york.jpg in 0.2522287368774414 seconds.\n",
      "All images stylized and saved in images/input\\output\\Van\\coco1_att\n"
     ]
    }
   ],
   "source": [
    "#resized con limiti massimi stimati \n",
    "# Clean up GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Path to the pre-trained style transformer model\n",
    "STYLE_TRANSFORM_PATH = \"/DL3/content/Van/coco1_att/transformer_weight.pth\"\n",
    "#STYLE_TRANSFORM_PATH = \"/DL3/content/Van/coco2/checkpoint_16000.pth\"\n",
    "# Set to True to preserve original content image colors, False to use style image colors\n",
    "PRESERVE_COLOR = True\n",
    "#set the max_size = to a value of pixel\n",
    "#limite massimo per 16gb 700*700, se le immagini sono 16:9 limite suggerito \n",
    "\n",
    "\n",
    "def resize_image(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "\n",
    "        # Calcolo del rapporto di aspetto\n",
    "        aspect_ratio = width / height\n",
    "        if width > height:\n",
    "            aspect_ratio = width / height\n",
    "        else:\n",
    "            aspect_ratio = height / width\n",
    "\n",
    "        # Definizione del limite massimo in base al rapporto di aspetto\n",
    "        if aspect_ratio >= 16/9:\n",
    "            max_size = 900\n",
    "        else:\n",
    "            max_size = 700  # Limite predefinito se il rapporto non è 16:9 o 1:1\n",
    "\n",
    "        # Verifica se il ridimensionamento è necessario\n",
    "        if max(width, height) > max_size:\n",
    "            if width > height:\n",
    "                new_width = max_size\n",
    "                new_height = int(max_size * height / width)\n",
    "            else:\n",
    "                new_height = max_size\n",
    "                new_width = int(max_size * width / height)\n",
    "            \n",
    "            resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "            \n",
    "            # Crea la sottocartella 'resized'\n",
    "            resized_folder = os.path.join(os.path.dirname(image_path), 'resized')\n",
    "            os.makedirs(resized_folder, exist_ok=True)\n",
    "            \n",
    "            # Salva l'immagine ridimensionata con suffisso \"_resized\" nella sottocartella 'resized'\n",
    "            base_name, ext = os.path.splitext(os.path.basename(image_path))\n",
    "            resized_image_path = os.path.join(resized_folder, f\"{base_name}_resized{ext}\")\n",
    "            resized_img.save(resized_image_path)\n",
    "            print(f\"Resized {image_path} to {new_width}x{new_height} and saved as {resized_image_path}.\")\n",
    "            return resized_image_path\n",
    "        return image_path\n",
    "\n",
    "\n",
    "def stylize_folder(content_folder, style_transform_path, preserve_color=False):\n",
    "    \"\"\"\n",
    "    Stylizes all images in the content_folder and saves them in new nested folders based on the\n",
    "    style_transform_path.\n",
    "    \n",
    "    Parameters:\n",
    "    - content_folder: Path to the folder containing content images.\n",
    "    - style_transform_path: Path to the style transformer model.\n",
    "    - preserve_color: Boolean indicating whether to preserve the colors of the content images.\n",
    "    \"\"\"\n",
    "    # Device\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ##############################################################################################################################################################\n",
    "    # Load Transformer Network SELEZIONARE IL TRANF GIUSTO\n",
    "    ##############################################################################################################################################################\n",
    "    # Load the style transformer network weights and transfer the model to the chosen device.\n",
    "    net = transformer.TransformerNetworkTanhWithAttention()\n",
    "    net.load_state_dict(torch.load(style_transform_path))\n",
    "    net = net.to(device)\n",
    "\n",
    "    # Extract the first and second subfolder names from the style_transform_path\n",
    "    first_subfolder_name = style_transform_path.split('/')[3]\n",
    "    second_subfolder_name = '/'.join(style_transform_path.split('/')[4:-1])\n",
    "\n",
    "    # Create output folder with the extracted subfolder names\n",
    "    output_folder = os.path.join(content_folder, \"output\", first_subfolder_name, second_subfolder_name)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Stylize every image in the content folder\n",
    "    images = [img for img in os.listdir(content_folder) if img.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    with torch.no_grad():\n",
    "        for image_name in images:\n",
    "            content_image_path = os.path.join(content_folder, image_name)\n",
    "            \n",
    "            # Resize image if necessary and get the path of the resized image\n",
    "            resized_image_path = resize_image(content_image_path)\n",
    "\n",
    "            try:\n",
    "                # Free-up unneeded cuda memory\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # Load content image\n",
    "                content_image = utils.load_image(resized_image_path)\n",
    "                content_tensor = utils.itot(content_image).to(device)\n",
    "\n",
    "                # Generate stylized image\n",
    "                starttime = time.time()\n",
    "                generated_tensor = net(content_tensor)\n",
    "                generated_image = utils.ttoi(generated_tensor.detach())\n",
    "                if preserve_color:\n",
    "                    generated_image = utils.transfer_color(content_image, generated_image)\n",
    "                print(f\"Stylized {image_name} in {time.time() - starttime} seconds.\")\n",
    "\n",
    "                # Save stylized image\n",
    "                output_image_path = os.path.join(output_folder, image_name)\n",
    "                utils.saveimg(generated_image, output_image_path)\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                # Catch out-of-memory errors and print the error\n",
    "                if 'out of memory' in str(e):\n",
    "                    print(f\"Error processing {image_name}: {e}.\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    print(f\"All images stylized and saved in {output_folder}\")\n",
    "\n",
    "# Example usage\n",
    "content_folder = input(\"Enter the folder path containing the images: \")\n",
    "stylize_folder(content_folder, STYLE_TRANSFORM_PATH, PRESERVE_COLOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb87b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
